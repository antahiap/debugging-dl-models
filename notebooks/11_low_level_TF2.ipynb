{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_tarin, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_tarin/255., x_test/255.\n",
    "\n",
    "x_train = tf.expand_dims(x_train[:10000].astype(\"float32\"), axis=-1)\n",
    "x_test = tf.expand_dims(x_test[:10000].astype(\"float32\"), axis=-1)\n",
    "y_train, y_test = y_train[:10000], y_test[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, loss, optimizer):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
    "        self.dense2 = tf.keras.layers.Dense(10)\n",
    "    \n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "    def train_step(self, images, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(images)\n",
    "            loss = self.loss(labels, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables) # compute gradient of loss wrt train vars\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        return predictions, loss, gradients\n",
    "\n",
    "    def test_step(self, images, labels):\n",
    "        predictions = self(images)\n",
    "        loss = self.loss(labels, predictions)\n",
    "\n",
    "        return predictions, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(loss_object, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean()\n",
    "train_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean()\n",
    "test_acc = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.002075519412755966, Test loss: 0.1262732595205307, Train acc: 0.9995999932289124Test acc: 0.9684000015258789\n",
      "Epoch 2, Train loss: 0.0119366105645895, Test loss: 0.12689875066280365, Train acc: 0.9962999820709229Test acc: 0.9664999842643738\n",
      "Epoch 3, Train loss: 0.011574814096093178, Test loss: 0.15980853140354156, Train acc: 0.9965000152587891Test acc: 0.9634000062942505\n",
      "Epoch 4, Train loss: 0.004956850782036781, Test loss: 0.12483221292495728, Train acc: 0.9990000128746033Test acc: 0.9707000255584717\n",
      "Epoch 5, Train loss: 0.00042186968494206667, Test loss: 0.12149380892515182, Train acc: 1.0Test acc: 0.9721999764442444\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "writer = tf.summary.create_file_writer(\"summary/run_2\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_acc.reset_states()\n",
    "    test_acc.reset_states()\n",
    "\n",
    "    for train_images, train_labels in train_ds:\n",
    "        pred_train, loss_train, grads_train = model.train_step(train_images, train_labels)\n",
    "        train_loss(loss_train)\n",
    "        train_acc(train_labels, pred_train)\n",
    "\n",
    "    for test_images, test_labels in test_ds:\n",
    "        pred_test, loss_test = model.test_step(test_images, test_labels)\n",
    "        test_loss(loss_test)\n",
    "        test_acc(test_labels, pred_test)\n",
    "\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"Train loss: \", train_loss.result(), step=epoch)\n",
    "            tf.summary.scalar(\"\\nTest loss: \", test_loss.result(), step=epoch)\n",
    "            tf.summary.scalar(\"\\nTrain acc: \", train_acc.result(), step=epoch)\n",
    "            tf.summary.scalar(\"\\nTest acc: \", test_acc.result(), step=epoch)\n",
    "\n",
    "    message = (\n",
    "      f\"Epoch {epoch + 1}, Train loss: {train_loss.result()}, \"\n",
    "      f\"Test loss: {test_loss.result()}, Train acc: {train_acc.result()}\"\n",
    "      f\"Test acc: {test_acc.result()}\"\n",
    "    )\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-28 12:04:30.102175: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-28 12:04:30.141367: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-28 12:04:30.141813: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-28 12:04:30.735517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-28 12:04:31.580743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-28 12:04:31.581585: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/apakiman/Projects/dsr-b35/dsr-cv/envs/lib/python3.10/site-packages/tensorboard_data_server/bin/server: /lib64/libc.so.6: version `GLIBC_2.29' not found (required by /home/apakiman/Projects/dsr-b35/dsr-cv/envs/lib/python3.10/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/apakiman/Projects/dsr-b35/dsr-cv/envs/lib/python3.10/site-packages/tensorboard_data_server/bin/server: /lib64/libc.so.6: version `GLIBC_2.33' not found (required by /home/apakiman/Projects/dsr-b35/dsr-cv/envs/lib/python3.10/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/apakiman/Projects/dsr-b35/dsr-cv/envs/lib/python3.10/site-packages/tensorboard_data_server/bin/server: /lib64/libc.so.6: version `GLIBC_2.34' not found (required by /home/apakiman/Projects/dsr-b35/dsr-cv/envs/lib/python3.10/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/apakiman/Projects/dsr-b35/dsr-cv/envs/lib/python3.10/site-packages/tensorboard_data_server/bin/server: /lib64/libc.so.6: version `GLIBC_2.32' not found (required by /home/apakiman/Projects/dsr-b35/dsr-cv/envs/lib/python3.10/site-packages/tensorboard_data_server/bin/server)\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.13.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
